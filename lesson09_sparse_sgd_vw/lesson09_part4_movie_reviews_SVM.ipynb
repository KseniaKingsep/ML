{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ml_theme.png\">\n",
    "# Дополнительное профессиональное <br> образование НИУ ВШЭ\n",
    "#### Программа \"Практический анализ данных и машинное обучение\"\n",
    "<img src=\"../../img/faculty_logo.jpg\" height=\"240\" width=\"240\">\n",
    "## Автор материала: старший преподаватель Факультета Компьютерных Наук ВШЭ, программист-исследователь Mail.ru Group  Юрий Кашницкий\n",
    "</center>\n",
    "Материал распространяется на условиях лицензии <a href=\"https://opensource.org/licenses/MS-RL\">Ms-RL</a>. Можно использовать в любых целях, кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Занятие 9. Разреженные данные, онлайн-обучение</center>\n",
    "## <center>Часть 4. Классификация отзывов к фильмам с SVM и логистической регрессией</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "# отключим всякие предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузим данные [отсюда](https://yadi.sk/d/Tg1Tflur333iLr). В обучающей и тестовой выборках по 12500 тысяч хороших и плохих отзывов к фильмам.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# поменяйте путь к файлу\n",
    "reviews_train = load_files(\"C:/Users/Ksenia/OneDrive/ML_HSE_BIG/module3_advanced_ML/data/aclImdb/test/\")\n",
    "text_train, y_train = reviews_train.data, reviews_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in training data: 17239\n",
      "[12500  4739]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of documents in training data: %d\" % len(text_train))\n",
    "print(np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Системе не удается найти указанный путь: '/Users/yorko/Яндекс.Диск/ML/data/aclImdb/test/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ac97b1a3db63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# поменяйте путь к файлу\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreviews_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/Users/yorko/Яндекс.Диск/ML/data/aclImdb/test/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtext_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreviews_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreviews_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of documents in test data: %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\datasets\\base.py\u001b[0m in \u001b[0;36mload_files\u001b[0;34m(container_path, description, categories, load_content, shuffle, encoding, decode_error, random_state)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0mfilenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     folders = [f for f in sorted(listdir(container_path))\n\u001b[0m\u001b[1;32m    202\u001b[0m                if isdir(join(container_path, f))]\n\u001b[1;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [WinError 3] Системе не удается найти указанный путь: '/Users/yorko/Яндекс.Диск/ML/data/aclImdb/test/'"
     ]
    }
   ],
   "source": [
    "# поменяйте путь к файлу\n",
    "reviews_test = load_files(\"/Users/yorko/Яндекс.Диск/ML/data/aclImdb/test/\")\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "print(\"Number of documents in test data: %d\" % len(text_test))\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример отзыва и соответствующей метки.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'When one of my friends recommended this to me, raving about how well it was filmed, the underlying themes and the general greatness of the film, I obviously expected an amazing, at least entertaining film.<br /><br />The two hours I spent watching this turned out to be a huge disappointing waste of my time.<br /><br />I understand that this movie is meant to be surreal, but even in surreal movies, there is something which anchors it down, even if it is only in the slightest. This movie, on the other hand, felt forced and fake. A lot of the shots were unnecessary and watching it made me think the director was trying to hard to be artistic.<br /><br />The acting was poor, and the relationships between characters were not nearly developed enough. Maybe that\\'s just me missing something that others could see but I hadn\\'t even realised there was any sort of attraction between Dae su and Migo before they started getting at it like rabbits randomly half way through the film. Then again, maybe this film was just bad.<br /><br />I am not against violence in movies, but in this one, almost all of it was just unnecessary. Throughout all the fight scenes I felt myself cringing at how painfully clich\\xc3\\xa9 it all was.<br /><br />And the plot? The word laughable comes to mind. I would be amused if I hadn\\'t wasted two hours of my life following this poorly thought out and ridiculous plot. Despite all the movie\\'s flaws, by the end of it, I was expecting something interesting to conclude it. I won\\'t discuss the ending, because I wouldn\\'t want to \"spoil\" the movie for those who haven\\'t seen it. Just that the metaphor \"Be it a rock or a grain of sand, in water they sink as the same.\" cannot be used as an explanation for everything.<br /><br />This entire movie was made for shock value and shock value only. I just hope sooner or later people will stop being so pretentious and recognise a bad movie for what it is. I\\'ve seen many other great Korean films and it depresses me that people have hailed Oldboy as the best.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[4] # плохой отзыв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Beautiful images, propaganda and history as toy. The ingredients of this film, good, interesting but with many shadows. Politicall shadows. Jefferson is more than the hero of a mythical America. He is silhouette of a vision about life and society, an extraordinary thinker, teacher of large part of North America. In film is only Superman. The delicate contour of ideas are crushed. The subtle birth of essential truth is forgotten. And Jefferson is basic instrument for create a good image of American realities. The end,triumphal and fake, romance and heroic, is gun suicide of a story who may be tall with more wisdom. And the war against \"Avatar\" is another gray stain. For one who heard nothing about Jefferson, movie is a good beginning. For the others - disillusion. It is like the precious silk of a tailor. But the tailor is fascinating about silk and the clothes are only ordinary cloth. So, a sad experience. Slices of beauty and boring lakes, patriotic lesson and the crush of expectation. A film who must impressive. And the ash of a story who could be magnificent.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[3] # хороший отзыв"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Идея \"мешка слов\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../img/bag_of_words.svg\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Простой подсчет слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Составим словарь всех слов с помощью CountVectorizer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(text_train)\n",
    "\n",
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на примеры полученных \"слов\" (лучше их называть токенами). Видим, что многие важные этапы обработки текста мы тут пропустили.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cv.get_feature_names()[:50])\n",
    "print(cv.get_feature_names()[50000:50050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Закодируем предложения из текстов обучающей выборки индексами входящих слов. Используем разреженный формат.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = cv.transform(text_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, как преобразование подействовало на одно из предложений.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(text_train[19726])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train[19726].nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train[19726].nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Преобразуем так же тестовую выборку.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = cv.transform(text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучим логистическую регрессию и линейный SVM.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "logit = LogisticRegression(n_jobs=-1, random_state=7)\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "svm = LinearSVC(random_state=7)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на доли правильных ответов на обучающей и тестовой выборках.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "round(logit.score(X_train, y_train), 3), round(svm.score(X_train, y_train), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "round(logit.score(X_test, y_test), 3), round(svm.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_coefficients(classifier, feature_names, n_top_features=25):\n",
    "    # get coefficients with large absolute values \n",
    "    coef = classifier.coef_.ravel()\n",
    "    positive_coefficients = np.argsort(coef)[-n_top_features:]\n",
    "    negative_coefficients = np.argsort(coef)[:n_top_features]\n",
    "    interesting_coefficients = np.hstack([negative_coefficients, positive_coefficients])\n",
    "    # plot them\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = [\"red\" if c < 0 else \"blue\" for c in coef[interesting_coefficients]]\n",
    "    plt.bar(np.arange(2 * n_top_features), coef[interesting_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1, 1 + 2 * n_top_features), feature_names[interesting_coefficients], rotation=60, ha=\"right\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_grid_scores(grid, param_name):\n",
    "    plot(grid.param_grid[param_name], grid.cv_results_['mean_train_score'],\n",
    "        color='green', label='train')\n",
    "    plot(grid.param_grid[param_name], grid.cv_results_['mean_test_score'],\n",
    "        color='red', label='test')\n",
    "    legend();\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_coefficients(logit, cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_coefficients(svm, cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подберем коэффициент регуляризации для логистической регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "text_pipe_logit = make_pipeline(CountVectorizer(), LogisticRegression(n_jobs=-1, random_state=7))\n",
    "\n",
    "text_pipe_logit.fit(text_train, y_train)\n",
    "print(text_pipe_logit.score(text_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_logit = {'logisticregression__C': np.logspace(-5, 0, 6)}\n",
    "grid_logit = GridSearchCV(text_pipe_logit, param_grid_logit, cv=3, n_jobs=-1)\n",
    "\n",
    "grid_logit.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лучшее значение C и соответствующее качество на кросс-валидации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_logit.best_params_, grid_logit.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_grid_scores(grid_logit, 'logisticregression__C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**То же самое для LinearSVC.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "text_pipe_svm = make_pipeline(CountVectorizer(), LinearSVC(random_state=7))\n",
    "\n",
    "text_pipe_svm.fit(text_train, y_train)\n",
    "print(text_pipe_svm.score(text_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid_svm = {'linearsvc__C': np.logspace(-5, 0, 6)}\n",
    "grid_svm = GridSearchCV(text_pipe_svm, param_grid_svm, cv=3, n_jobs=-1)\n",
    "\n",
    "grid_svm.fit(text_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_svm.best_params_, grid_svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_grid_scores(grid_svm, 'linearsvc__C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_coefficients(grid_svm.best_estimator_.named_steps['linearsvc'],\n",
    "                       grid_svm.best_estimator_.named_steps['countvectorizer'].get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На валидационной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_logit.score(text_test, y_test), grid_svm.score(text_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_pipe = make_pipeline(TfidfVectorizer(), LinearSVC())\n",
    "\n",
    "param_grid = {'linearsvc__C': np.logspace(-3, 2, 6)}\n",
    "grid_tfidf = GridSearchCV(tfidf_pipe, param_grid, cv=3, n_jobs=-1)\n",
    "grid_tfidf.fit(text_train, y_train)\n",
    "plot_grid_scores(grid_tfidf, 'linearsvc__C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_coefficients(grid_tfidf.best_estimator_.named_steps['linearsvc'],\n",
    "                       grid_tfidf.best_estimator_.named_steps['tfidfvectorizer'].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_tfidf.best_score_, grid_tfidf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-граммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "text_pipe = make_pipeline(CountVectorizer(), LinearSVC())\n",
    "\n",
    "param_grid = {'linearsvc__C': [0.01, 0.1, 1],\n",
    "              \"countvectorizer__ngram_range\": [(1, 2)]}\n",
    "\n",
    "grid_bigram = GridSearchCV(text_pipe, param_grid, cv=3)\n",
    "\n",
    "grid_bigram.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_grid_scores(grid_bigram, 'linearsvc__C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_bigram.best_score_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
